{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71ece76",
   "metadata": {},
   "source": [
    "# Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86525f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dataset\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "\n",
    "# load the images\n",
    "def load_real_samples_train():\n",
    "    directory=\"/Users/mdsanowarhossain/Documents/coding_research/dataset/potato_training\"\n",
    "    category=[\"Early_Blight\",\"Healthy\",\"Late_Blight\"]\n",
    "    \n",
    "    data=[]\n",
    "    for cat in category:\n",
    "        newfolder=os.path.join(directory,cat)\n",
    "        #print(newfolder)\n",
    "        label=category.index(cat)\n",
    "        \n",
    "        for img in os.listdir(newfolder):\n",
    "            img=os.path.join(newfolder,img)\n",
    "            img_arr=cv2.imread(img)\n",
    "            img_arr=cv2.resize(img_arr,(32,32))\n",
    "            data.append([img_arr,label])\n",
    "            random.shuffle(data)\n",
    "        \n",
    "\n",
    "    #data split as dependent and independent\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for feature, label in data:\n",
    "        x.append(feature)\n",
    "        y.append(label)\n",
    "    #convert list to arrary\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "\n",
    "    # train_test spliting\n",
    "    #from sklearn.model_selection import train_test_split\n",
    "    #trainX,testX,trainy,testy=train_test_split(x,y,test_size=0.1,random_state=42)\n",
    "    \n",
    "    #img_arr=(img_arr-127.5)/127.5\n",
    "    X = expand_dims(x, axis=-1)\n",
    "    X = (X - 127.5) / 127.5\n",
    "    X = X.astype('float32')\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94bc9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=load_real_samples_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a8aae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0147ff",
   "metadata": {},
   "source": [
    "# Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df4689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation dataset\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "\n",
    "# load the images\n",
    "def load_real_samples_val():\n",
    "    directory=\"/Users/mdsanowarhossain/Documents/coding_research/dataset/Validation\"\n",
    "    category=[\"Early_Blight\",\"Healthy\",\"Late_Blight\"]\n",
    "    \n",
    "    data=[]\n",
    "    for cat in category:\n",
    "        newfolder=os.path.join(directory,cat)\n",
    "        #print(newfolder)\n",
    "        label=category.index(cat)\n",
    "        \n",
    "        for img in os.listdir(newfolder):\n",
    "            img=os.path.join(newfolder,img)\n",
    "            img_arr=cv2.imread(img)\n",
    "            img_arr=cv2.resize(img_arr,(32,32))\n",
    "            data.append([img_arr,label])\n",
    "            random.shuffle(data)\n",
    "        \n",
    "\n",
    "    #data split as dependent and independent\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for feature, label in data:\n",
    "        x.append(feature)\n",
    "        y.append(label)\n",
    "    #convert list to arrary\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "\n",
    "    # train_test spliting\n",
    "    #from sklearn.model_selection import train_test_split\n",
    "    #trainX,testX,trainy,testy=train_test_split(x,y,test_size=0.1,random_state=42)\n",
    "    \n",
    "    #img_arr=(img_arr-127.5)/127.5\n",
    "    X = expand_dims(x, axis=-1)\n",
    "    X = (X - 127.5) / 127.5\n",
    "    X = X.astype('float32')\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c9b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=load_real_samples_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e450bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662ddab",
   "metadata": {},
   "source": [
    "# Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c98b235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing dataset\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "\n",
    "# load the images\n",
    "def load_real_samples_test():\n",
    "    directory=\"/Users/mdsanowarhossain/Documents/coding_research/dataset/Testing\"\n",
    "    category=[\"Early_Blight\",\"Healthy\",\"Late_Blight\"]\n",
    "    \n",
    "    data=[]\n",
    "    for cat in category:\n",
    "        newfolder=os.path.join(directory,cat)\n",
    "        #print(newfolder)\n",
    "        label=category.index(cat)\n",
    "        \n",
    "        for img in os.listdir(newfolder):\n",
    "            img=os.path.join(newfolder,img)\n",
    "            img_arr=cv2.imread(img)\n",
    "            img_arr=cv2.resize(img_arr,(32,32))\n",
    "            data.append([img_arr,label])\n",
    "            random.shuffle(data)\n",
    "        \n",
    "\n",
    "    #data split as dependent and independent\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for feature, label in data:\n",
    "        x.append(feature)\n",
    "        y.append(label)\n",
    "    #convert list to arrary\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "\n",
    "    # train_test spliting\n",
    "    #from sklearn.model_selection import train_test_split\n",
    "    #trainX,testX,trainy,testy=train_test_split(x,y,test_size=0.1,random_state=42)\n",
    "    \n",
    "    #img_arr=(img_arr-127.5)/127.5\n",
    "    X = expand_dims(x, axis=-1)\n",
    "    X = (X - 127.5) / 127.5\n",
    "    X = X.astype('float32')\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea030e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=load_real_samples_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c3c5069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 2, 2, 0, 0, 0, 0, 1, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 2, 0, 0, 1, 0, 1, 0, 2, 1, 2, 2, 0, 0, 1, 2, 1, 0, 1, 2,\n",
       "       1, 0, 2, 1, 0, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2,\n",
       "       0, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 0, 2, 0, 0, 2, 2, 2, 2, 0,\n",
       "       1, 1, 1, 0, 2, 0, 1, 2, 2, 1, 2, 0, 0, 1, 0, 0, 2, 1, 2, 1, 0, 0,\n",
       "       2, 2, 1, 0, 0, 1, 2, 1, 1, 0, 0, 2, 2, 0, 1, 0, 0, 2, 1, 1, 1, 2,\n",
       "       2, 2, 0, 2, 0, 1, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 0, 0, 2, 2,\n",
       "       2, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 2, 0, 0, 2, 1, 2,\n",
       "       2, 1, 0, 1, 0, 2, 0, 0, 2, 1, 2, 1, 2, 2, 0, 1, 2, 0, 0, 0, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 0, 2, 2, 0, 1, 1, 0, 0, 0, 0, 2, 1, 2, 0, 2, 0,\n",
       "       2, 2, 1, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 0, 0, 2, 0, 2, 0, 0, 1, 2,\n",
       "       2, 1, 0, 1, 2, 1, 2, 0, 1, 2, 1, 1, 1, 1, 1, 0, 2, 2, 0, 0, 2, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 2, 2, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 0, 0,\n",
       "       2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 1, 0, 0, 2, 2, 0,\n",
       "       1, 1, 1, 0, 2, 2, 0, 0, 0, 1, 2, 1, 2, 0, 2, 2, 1, 0, 0, 1, 0, 2,\n",
       "       0, 0, 0, 1, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0,\n",
       "       2, 0, 2, 0, 2, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268aac37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
